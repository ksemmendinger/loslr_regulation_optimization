# import libraries
import os
import sys
import numpy as np
import pandas as pd
from pathlib import Path
from os.path import exists

# set variables from command line input
args = sys.argv
# args = ["", "mac_loc", "5", "12month", "sqAR", "30000", "17"]
# args = [ "", "mac_loc", "rc12month", "5", "historic", "12month", "0", "50000", "6", "12"]

nobjs = 7

# -----------------------------------------------------------------------------
# experiment setup
# -----------------------------------------------------------------------------

# operating system
loc = args[1]

# number of seeds
nseed = int(args[2])

# forecast lead-time
leadtime = args[3]

# forecast skill
skill = args[4]

# number of function evaluations
nfe = int(args[5])

# number of decision variables
nvars = int(args[6])

# folder name
folderName = leadtime + "_" + str(skill) + "_" + str(nfe) + "nfe_" + str(nvars) + "dvs"

# set working directory
if args[1] == "mac_loc":
    wd = "/Users/kylasemmendinger/Library/CloudStorage/Box-Box/Plan_2014/optimization/output"
elif args[1] == "hopper":
    wd = "/home/fs02/pmr82_0001/kts48/optimization/output"
os.chdir(wd)

# names of objectives
pis = [
    "Coastal Impacts: Upstream Buildings Impacted (#)",
    "Coastal Impacts: Downstream Buildings Impacted (#)",
    "Commercial Navigation: Ontario + Seaway + Montreal Transportation Costs ($)",
    "Hydropower: Moses-Saunders + Niagara Energy Value ($)",
    "Meadow Marsh: Area (ha)",
    "Muskrat House Density (#/ha)",
    "Recreational Boating: Impact Costs ($)",
]

# names of decision variables
dvs = [
    "Rule Curve Wet Multiplier",
    "Rule Curve Confident Wet Multiplier",
    "Rule Curve Dry Multiplier",
    "Rule Curve Wet Power",
    "Rule Curve Dry Power",
    "Rule Curve Threshold",
    "Rule Curve Wet Adjustment",
    "Rule Curve Dry Adjustment",
    "Rule Curve Low Level Threshold",
    "Rule Curve Low Level Flow Adjustment",
    "Long Forecast Wet Threshold",
    "Long Forecast Dry Threshold",
    "Long Forecast 50% Confidence Interval",
    "Long Forecast 99% Confidence Interval",
    "R+ Threshold",
    "R+ Starting Quarter-Month",
    "R+ Ending Quarter-Month",
]


# create folder for clean decision variable and objective files
newpath = "data/" + folderName + "/clean/"
if not os.path.exists(newpath):
    os.makedirs(newpath)

# create folder for moeaFramework
# parent directory
newpath = "data/" + folderName + "/moeaFramework/"
if not os.path.exists(newpath):
    os.makedirs(newpath)

# inputs
newpath = "data/" + folderName + "/moeaFramework/objs/"
if not os.path.exists(newpath):
    os.makedirs(newpath)

# outputs
newpath = "data/" + folderName + "/moeaFramework/metrics/"
if not os.path.exists(newpath):
    os.makedirs(newpath)

# -----------------------------------------------------------------------------
# find nondominated policies
# -----------------------------------------------------------------------------

# find non dominated solutions across all pareto fronts generated by all seeds
def is_pareto_efficient(costs, return_mask=True):

    # find the pareto-efficient points
    # costs: (n_points, n_costs) array
    # return_mask: True to return a mask
    # return: array of indices of pareto-efficient points. if return_mask is
    # True, this will be an (n_points, ) boolean array. otherwise it will be
    # a (n_efficient_points, ) integer array of indices

    is_efficient = np.arange(costs.shape[0])
    n_points = costs.shape[0]

    # next index in the is_efficient array to search for
    next_point_index = 0
    while next_point_index < len(costs):
        nondominated_point_mask = np.any(costs < costs[next_point_index], axis=1)
        nondominated_point_mask[next_point_index] = True
        # remove dominated points
        is_efficient = is_efficient[nondominated_point_mask]
        costs = costs[nondominated_point_mask]
        next_point_index = np.sum(nondominated_point_mask[:next_point_index]) + 1
    if return_mask:
        is_efficient_mask = np.zeros(n_points, dtype=bool)
        is_efficient_mask[is_efficient] = True
        return is_efficient_mask
    else:
        return is_efficient


# -----------------------------------------------------------------------------
# format raw borg output files
# -----------------------------------------------------------------------------

pf = []
dvpf = []

for s in range(nseed):

    # first, check to see if complete run
    path = Path("data/" + folderName + "/raw/pareto_front_S" + str(s + 1) + ".txt")

    # if yes, load discovered pareto front for the seed of interest
    if path.is_file():

        pfSeed = pd.read_csv(
            "data/" + folderName + "/raw/pareto_front_S" + str(s + 1) + ".txt",
            sep=" ",
            header=None,
            skiprows=2,
        )

    # if not, take last pareto front from runtime file
    else:

        import csv

        fn = "data/" + folderName + "/raw/runtime_S" + str(s + 1) + ".txt"
        data = []
        flag = False
        with open(fn) as f:
            for line in reversed(f.readlines()):
                if line.startswith("#"):
                    flag = True
                    continue
                elif line.startswith("//"):
                    flag = False
                    break
                if flag:
                    data.append(line)

        # convert to data frame
        pfSeed = pd.DataFrame([[float(x) for x in e.split()] for e in data])
        pfSeed = pfSeed.iloc[:, 1:]

        tmp = pfSeed[pfSeed.columns[0:]].apply(
            lambda x: " ".join(x.dropna().astype(str)), axis=1
        )

        tmp = pd.DataFrame(tmp)

        # add in beginning lines
        line1 = "#Borg Optimization Results"
        line2 = (
            "#First "
            + str(nvars)
            + " are the decision variables, last "
            + str(nobjs)
            + " are the objective values"
        )

        lines = pd.DataFrame([line1, line2])

        tmp = pd.concat([lines, tmp])

        # save to csv
        tmp.to_csv(
            "data/" + folderName + "/raw/pareto_front_S" + str(s + 1) + ".txt",
            index=False,
            header=False,
            quoting=csv.QUOTE_NONE,
            escapechar="\\",
        )

    # drop columns with NAs (usually just a weird output from borg)
    pfSeed = pfSeed.dropna(axis=1, how="all")
    pfSeed = pfSeed.dropna(axis=0, how="any")

    # set column names
    pfSeed.columns = dvs + pis

    # save clean pareto front to file for reference later
    pfSeed.to_csv(
        "data/" + folderName + "/clean/pareto_front_S" + str(s + 1) + ".txt",
        sep=",",
        header=True,
        index=False,
    )

    pfSeed.insert(0, "Policy", s + 1)
    dvpf.append(pfSeed)

    # extract just objectives and save in text file with # at the end for use in the MOEAFramework
    objSeed = pfSeed[pis]
    objSeed.to_csv(
        "data/"
        + folderName
        + "/moeaFramework/objs/pareto_front_S"
        + str(s + 1)
        + ".txt",
        sep=" ",
        header=False,
        index=False,
    )

    with open(
        "data/"
        + folderName
        + "/moeaFramework/objs/pareto_front_S"
        + str(s + 1)
        + ".txt",
        "a",
    ) as f:
        f.write("#")

    pf.append(objSeed)

# -----------------------------------------------------------------------------
# update or create reference set for MOEAFramework
# -----------------------------------------------------------------------------

# # check to see if the reference set exists
# if exists("data/" + folderName + "/moeaFramework/objRefset.txt"):

#     # update reference set with new pareto fronts
#     refset = pd.read_csv(
#         "data/" + folderName + "/moeaFramework/objRefset.txt", header=None, sep=" "
#     )
#     refset = refset.dropna()
#     refset.columns = pis

#     # join all seeded pareto fronts into one data frame
#     pf = pd.concat(pf).reset_index(drop=True)

#     # join reference set with newly discovered pareto fronts
#     objsDF = pd.concat([pf, refset]).reset_index(drop=True)

# else:
#     # join all seeded pareto fronts into one data frame
#     objsDF = pd.concat(pf).reset_index(drop=True)

# join all seeded pareto fronts into one data frame
objsDF = pd.concat(pf).reset_index(drop=True)

objs = objsDF.to_numpy(dtype="float")

# find reference set (non-dominated policies across all seeds)
refsetInd = is_pareto_efficient(objs, return_mask=True)
refsetInd = pd.Series(refsetInd)
refsetUpdated = objsDF[refsetInd].reset_index(drop=True)

refsetUpdated.to_csv(
    "data/" + folderName + "/moeaFramework/objRefset.txt",
    sep=" ",
    header=False,
    index=False,
)

with open("data/" + folderName + "/moeaFramework/objRefset.txt", "a") as f:
    f.write("#")

# -----------------------------------------------------------------------------
# save nondominated policies with decision variables
# -----------------------------------------------------------------------------

# join all seeded pareto fronts into one data frame
pols = pd.concat(dvpf).reset_index(drop=True)
objs = pols[pis].to_numpy(dtype="float")

# find reference set
refsetInd = is_pareto_efficient(objs, return_mask=True)
refsetInd = pd.Series(refsetInd)
refsetUpdated = pols[refsetInd].reset_index(drop=True)

# join all seeded pareto fronts into one data frame
if skill == "0":
    prettySkill = "Perfect"
elif skill == "sqLM":
    prettySkill = "Status Quo (LM)"
elif skill == "sqAR":
    prettySkill = "Status Quo (AR)"
else:
    prettySkill = skill

refsetUpdated.insert(0, "ID", range(0, refsetUpdated.shape[0]))
refsetUpdated.insert(0, "Skill", prettySkill)
refsetUpdated.insert(0, "Lead-Time", leadtime.split("month")[0] + "-month")
refsetUpdated.insert(
    0, "Experiment", refsetUpdated["Lead-Time"] + " " + refsetUpdated["Skill"]
)

# save updated reference set
refsetUpdated.to_csv(
    "data/" + folderName + "/NonDominatedPolicies.txt",
    sep="\t",
    header=True,
    index=False,
)

# # -----------------------------------------------------------------------------
# # update overall nondominated policies across all forecast lead-times and skills
# # -----------------------------------------------------------------------------

# # join all seeded pareto fronts into one data frame
# if skill == "0":
#     prettySkill = "Perfect"
# elif skill == "sqLM":
#     prettySkill = "Status Quo (LM)"
# elif skill == "sqAR":
#     prettySkill = "Status Quo (AR)"
# else:
#     prettySkill = skill

# pols = refsetUpdated.copy()
# pols.insert(0, "Experiment", leadtime.split("month")[0] + "-month" + " " + prettySkill)

# # check to see if the reference set exists
# if exists("data/NonDominatedPolicies.txt"):

#     # update reference set with new pareto fronts
#     refset = pd.read_csv("data/NonDominatedPolicies.txt", sep="\t")
#     refset = refset.dropna()

#     # join reference set with newly discovered pareto fronts
#     pols = pd.concat([refset, pols]).reset_index(drop=True)

# # extract obejctive values
# objs = pols[pis].to_numpy(dtype="float")

# # find reference set
# refsetInd = is_pareto_efficient(objs, return_mask=True)
# refsetInd = pd.Series(refsetInd)
# refsetUpdated = pols[refsetInd].reset_index(drop=True)

# # save updated reference set
# refsetUpdated.to_csv(
#     "data/NonDominatedPolicies.txt",
#     sep="\t",
#     header=True,
#     index=False,
# )

# -----------------------------------------------------------------------------
# extract objectives from runtime files
# -----------------------------------------------------------------------------

for s in range(nseed):

    # load runtime dynamics and pareto fronts for seed of interest line by line
    rtSeed = []
    dynSeed = []

    with open("data/" + folderName + "/raw/runtime_S" + str(s + 1) + ".txt") as f:
        for line in f:
            # check if the current line starts with "//" to signal runtime dynamics
            if line.startswith("//"):
                line = line.replace("\n", "")
                dynSeed.append(line)
            elif not line.startswith("#"):
                line = line.replace("\n", "")
                rtSeed.append(line)

    # save clean runtime dynamics to file for reference later
    dynSeed = pd.DataFrame(dynSeed)
    dynSeed.to_csv(
        "data/" + folderName + "/clean/dynamics_S" + str(s + 1) + ".txt",
        sep=",",
        header=False,
        index=False,
    )

    # format to data frame and set column names
    rtSeed = pd.DataFrame([[float(x) for x in e.split()] for e in rtSeed])
    rtSeed.columns = ["NFE"] + dvs + pis

    # save clean output to file for reference later
    rtSeed.to_csv(
        "data/" + folderName + "/clean/runtime_S" + str(s + 1) + ".txt",
        sep=",",
        header=True,
        index=False,
    )

    # save objectives only to evaluate in MOEAFramework
    freq = rtSeed["NFE"].unique()

    for fe in range(len(freq)):

        # filter by NFE of interest and extract objectives
        tmp = rtSeed.loc[rtSeed["NFE"] == freq[fe]]
        tmp = tmp[pis]

        filename = (
            "data/" + folderName + "/moeaFramework/objs/runtime_S" + str(s + 1) + ".txt"
        )

        if fe == 0:
            tmp.to_csv(filename, sep=" ", index=False, header=False)
        else:
            tmp.to_csv(filename, sep=" ", index=False, header=False, mode="a")

        with open(filename, "a") as f:
            f.write("#\n")
